import os
import requests
import re
from typing import Dict, Any, List
from dotenv import load_dotenv
import logging
from modules.rag_chatbot import RAGChatbot, get_chatbot_instance
from langchain.schema.document import Document

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
import sys
hybrid_logger = logging.getLogger('hybrid_chatbot')
hybrid_logger.setLevel(logging.INFO)

# ê¸°ì¡´ í•¸ë“¤ëŸ¬ê°€ ìˆë‹¤ë©´ ì œê±°
for handler in hybrid_logger.handlers[:]:
    hybrid_logger.removeHandler(handler)

# íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
file_handler = logging.FileHandler('logs/hybrid_chatbot.log')
file_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
hybrid_logger.addHandler(file_handler)

# ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€ (ë””ë²„ê¹…ìš©)
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
hybrid_logger.addHandler(console_handler)

logger = hybrid_logger

class HybridChatbot(RAGChatbot):
    """
    RAG + Perplexity APIë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì±—ë´‡
    """
    def __init__(self):
        super().__init__()
        self.perplexity_api_key = os.getenv("PERPLEXITY_API_KEY")
        
        if not self.perplexity_api_key:
            logger.warning("PERPLEXITY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    
    def search_with_perplexity(self, query: str) -> Dict[str, Any]:
        """Perplexity APIë¡œ ì‹¤ì‹œê°„ ê²€ìƒ‰"""
        if not self.perplexity_api_key:
            return {"content": None, "error": "Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        url = "https://api.perplexity.ai/chat/completions"
        
        # ê²½ì œ ê´€ë ¨ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™”
        optimized_query = f"{query} í•œêµ­ ê²½ì œ ê¸ˆìœµ ìµœì‹  ë‰´ìŠ¤"
        
        payload = {
            "model": "llama-3.1-sonar-small-128k-online",  # ì˜¨ë¼ì¸ ê²€ìƒ‰ ëª¨ë¸
            "messages": [
                {
                    "role": "system", 
                    "content": "ë‹¹ì‹ ì€ í•œêµ­ ê²½ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìµœì‹  ê²½ì œ ë™í–¥ê³¼ ê¸ˆìœµ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
                },
                {"role": "user", "content": optimized_query}
            ],
            "max_tokens": 1000,
            "temperature": 0.3,
            "stream": False
        }
        
        headers = {
            "Authorization": f"Bearer {self.perplexity_api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers)
            response.raise_for_status()
            
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            logger.info(f"Perplexity ê²€ìƒ‰ ì„±ê³µ: {query[:30]}...")
            return {"content": content, "error": None}
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Perplexity API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            return {"content": None, "error": str(e)}
    
    def _is_recent_info_needed(self, query: str) -> bool:
        """ìµœì‹  ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
        recent_keywords = [
            "ìµœê·¼", "í˜„ì¬", "ì˜¤ëŠ˜", "ì§€ê¸ˆ", "ìµœì‹ ", "ìš”ì¦˜", 
            "ì´ë²ˆ", "ì–´ì œ", "ë‚´ì¼", "ì£¼ê°€", "í™˜ìœ¨", "ì‹œì„¸",
            "ë™í–¥", "ì „ë§", "ì˜ˆì¸¡", "ì‹¤ì‹œê°„", "ì†ë³´"
        ]
        
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in recent_keywords)
    
    def _is_economy_related(self, query: str) -> bool:
        """ê²½ì œ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
        economy_keywords = [
            "ê²½ì œ", "ê¸ˆìœµ", "ì£¼ì‹", "íˆ¬ì", "ì±„ê¶Œ", "í™˜ìœ¨", 
            "ê¸ˆë¦¬", "ì¸í”Œë ˆì´ì…˜", "ë””í”Œë ˆì´ì…˜", "GDP", "ë¬¼ê°€",
            "ë¶€ë™ì‚°", "í€ë“œ", "ì˜ˆê¸ˆ", "ì ê¸ˆ", "ë³´í—˜", "ì—°ê¸ˆ",
            "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "ETF", "ë¦¬ì¸ ", "ì€í–‰", "ì¦ê¶Œ"
        ]
        
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in economy_keywords)
    
    def _combine_contexts(self, rag_docs: List[Document], perplexity_result: str) -> str:
        """RAG ë¬¸ì„œì™€ Perplexity ê²°ê³¼ ê²°í•©"""
        context_parts = []
        
        # RAG ë¬¸ì„œ ë‚´ìš©
        if rag_docs:
            context_parts.append("=== ë‚´ë¶€ ì§€ì‹ ë² ì´ìŠ¤ ===")
            for i, doc in enumerate(rag_docs[:3]):  # ìƒìœ„ 3ê°œë§Œ
                context_parts.append(f"\n[ë¬¸ì„œ {i+1}: {doc.metadata.get('title', 'Unknown')}]")
                context_parts.append(doc.page_content[:500] + "...")
        
        # Perplexity ê²€ìƒ‰ ê²°ê³¼
        if perplexity_result:
            context_parts.append("\n\n=== ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ê²°ê³¼ ===")
            context_parts.append(perplexity_result)
        
        return "\n".join(context_parts)
    
    def get_answer(self, query: str) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ë‹µë³€ ìƒì„±"""
        logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ì²˜ë¦¬: {query}")
        
        # 1. ê²½ì œ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        if not self._is_economy_related(query):
            return {
                "answer": "ì£„ì†¡í•˜ì§€ë§Œ ê²½ì œ, íˆ¬ì, ê¸ˆìœµ ê´€ë ¨ ì§ˆë¬¸ë§Œ ë‹µë³€í•  ìˆ˜ ìˆì–´ìš©~ ğŸ¦– ë‹¤ë¥¸ ê²½ì œ ê´€ë ¨ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš©!",
                "sources": {"type": "filtered", "reason": "ê²½ì œ ë¬´ê´€"}
            }
        
        # 2. ê¸°ì¡´ RAGë¡œ ë¬¸ì„œ ê²€ìƒ‰
        rag_docs = self.multiquery_retriever.get_relevant_documents(query)
        
        # 3. ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ RAG ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°
        need_web_search = (
            self._is_recent_info_needed(query) or 
            len(rag_docs) < 2 or
            not rag_docs
        )
        
        perplexity_result = None
        if need_web_search and self.perplexity_api_key:
            search_result = self.search_with_perplexity(query)
            perplexity_result = search_result.get("content")
        
        # 4. ì»¨í…ìŠ¤íŠ¸ ê²°í•©
        if perplexity_result:
            combined_context = self._combine_contexts(rag_docs, perplexity_result)
            
            # ê²°í•©ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
            prompt = f"""
            ë‹¹ì‹ ì€ ê²½ì œ ì „ë¬¸ AI ì±—ë´‡ 'ê²½ì œìš©'ì…ë‹ˆë‹¤. 
            ì œê³µëœ ë‚´ë¶€ ì§€ì‹ê³¼ ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
            ê°€ë” '~ìš©' ê°™ì€ ê·€ì—¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
            
            ì»¨í…ìŠ¤íŠ¸:
            {combined_context}
            
            ì§ˆë¬¸: {query}
            
            ë‹µë³€:
            """
            
            response = self.llm.invoke(prompt)
            answer = response.content
            
            sources = {
                "type": "hybrid",
                "internal_docs": [
                    {
                        "title": doc.metadata.get("title", "Unknown"),
                        "source_type": doc.metadata.get("source_type", "")
                    } for doc in rag_docs[:3]
                ],
                "web_search": "Perplexity API ì‹¤ì‹œê°„ ê²€ìƒ‰ í¬í•¨"
            }
        else:
            # RAGë§Œìœ¼ë¡œ ë‹µë³€ ìƒì„±
            answer_result = super().get_answer(query)
            answer = answer_result["answer"]
            sources = {
                "type": "rag_only",
                "internal_docs": answer_result["related_docs"]
            }
        
        return {
            "answer": answer,
            "sources": sources
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_hybrid_chatbot_instance = None

def get_hybrid_chatbot_instance():
    """í•˜ì´ë¸Œë¦¬ë“œ ì±—ë´‡ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _hybrid_chatbot_instance
    
    if _hybrid_chatbot_instance is None:
        _hybrid_chatbot_instance = HybridChatbot()
        
    return _hybrid_chatbot_instance

def initialize_hybrid_chatbot():
    """í•˜ì´ë¸Œë¦¬ë“œ ì±—ë´‡ ì´ˆê¸°í™”"""
    try:
        chatbot = get_hybrid_chatbot_instance()
        chatbot.load_documents()
        chatbot.create_chunks_and_index()
        chatbot.setup_rag_chain()
        logger.info("í•˜ì´ë¸Œë¦¬ë“œ ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì±—ë´‡ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
    import json
    
    # ì´ˆê¸°í™”
    initialize_hybrid_chatbot()
    chatbot = get_hybrid_chatbot_instance()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_queries = [
        "ETFê°€ ë¬´ì—‡ì¸ê°€ìš”?",  # ê¸°ë³¸ RAG ì§ˆë¬¸
        "ì˜¤ëŠ˜ ì½”ìŠ¤í”¼ ì§€ìˆ˜ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",  # ì‹¤ì‹œê°„ ì •ë³´ í•„ìš”
        "ìµœê·¼ í•œêµ­ ê²½ì œ ë™í–¥ì€ ì–´ë–¤ê°€ìš”?",  # ìµœì‹  ì •ë³´ í•„ìš”
    ]
    
    for query in test_queries:
        print(f"\nì§ˆë¬¸: {query}")
        result = chatbot.get_answer(query)
        print(f"ë‹µë³€: {result['answer'][:100]}...")
        print(f"ì¶œì²˜: {result['sources']['type']}")